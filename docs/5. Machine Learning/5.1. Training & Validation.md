# 5.1. Training & Validation

# Abstract training pipeline / config files

The majority of code when training and validation can be moved into functions to be reused across models. 

Then the settings for each model, the response, exposure (if using), weighting, features, loss function, hyperparameters, can be stored in configuration files. 

---

# Gradient Boosting Machines

GBMs are highly performant on predictive modelling for tabular data. 

There are a number of GBM libraries that are popular, CatBoost generally out performs XGBoost and LightGBM whilst also having easier implementation due to the way it handles categorical factors.

---

# Plots

We still need to perform validation to ensure our models are sensible. 

SHAP is widely used for feature importance. And showing how factor is fitted. 

We also want to be building plots for calibration and any other aspect of the model performance we wish to view.

We list through the feature list and dynamically generate all v alidation plots for each model that we build.

---

# Metrics

Binomial Classification - ROC, AUC, Lift 

Multinomical Classification - 

Poission Regression - 

Gamma Regression -

Regression - 

---

# Experiment Tracking

One aspect of data science that is yet to become popular in pricing is the concept of experiment tracking. 

This is where for each training run, we track every required to reproduce the model (features, parameters, datasets) along with the performance of the model. 

---

# Model metadata

When we wish to use models later on, having everything required to easily reproduce the predictions. 

Ie a model may be built with a certain amount of features, and more recent iterations of the model contain a different set. 

When scoring the models, we often need to provide a dataset with only the features that are used, and so having this available automatically is very useful. 

This is also important for models that feed other models. For example a Conversion model may have inputs from Competitor Models, and so we can include in the metadata for each Conversion experiment which version of the Conversion models were used. 

