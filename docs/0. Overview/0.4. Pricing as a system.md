# 0.4. Pricing as a system

Insurance pricing can be very piecemeal. 

A new analysis is needed, so a new folder and spreadsheet is made. A dataset is needed, so a new query is written. A model hasn't been refreshed in a year, so a couple of weeks are set aside to build. Performance has dropped, tasks are deprioritised to investigate. There's a new set of vehicle classification data, so all instances where this is used need updating.

Over time, these one-off projects accumulate into a maze of disconnected tools, datasets, and documents.  

They might each work individually - but together, they form a fragile, hard-to-maintain landscape.

By contrast, thinking of pricing as a system changes the approach entirely.  

It shifts focus from delivering isolated outputs to building a connected, maintainable framework where every component plays a role in a larger whole.

---

## Avoiding standalone ad-hoc analysis

An ad-hoc approach might seem faster in the short term, but it comes with hidden costs:

- Duplication of effort - analysts rebuild similar processes for each new request.
- Inconsistency - slightly different methods and assumptions creep into each analysis.
- Lack of reproducibility - outputs can’t be regenerated without repeating the entire manual process.
- Single points of failure - if the creator leaves, knowledge of how it works disappears.
- No long term improvement - each item only produces short term benefit, without improving workflows, tools or future analysis.

By designing processes so they can be plugged into a wider system, you reduce the risk of error, shorten delivery times, and make it easier to evolve your pricing over time.

---

## Pricing Architecture

Pricing architecture is the blueprint for how your pricing process works end-to-end.  
It defines:

- Data flows - where data comes from, how it’s cleaned, and how it’s made available for modelling.
- Model lifecycle - how models are trained, validated, deployed, and monitored.
- Business logic - the rules and adjustments applied outside of statistical models.
- Output delivery - how reports, validation, and diagnostics are generated and distributed.
- Deployment - how prices are code are updated and deployed.

A good architecture ensures each component is connected, auditable, and repeatable.

This doesn’t mean building the most complex system possible - it means making the system coherent and maintainable.

---

## Modular components that can be reused

At the heart of a pricing system are modular components - small, well-defined processes that can be reused in multiple contexts and integrate well.  

Examples include:

- Data loaders that can be pointed at any dataset in a standard format.
- Feature engineering scripts that can be applied across multiple product lines.
- Model training pipelines that can work with different algorithms without rewriting everything.
- Report generators that can produce consistent outputs for different stakeholders.
- Impact analysis module that is used for each price change.

Benefits of modular design:

- Reusability - the same code can be applied to different products or datasets.
- Maintainability - fixes and improvements are made in one place and used everywhere.
- Scalability - new capabilities can be added without breaking existing processes.
- Speed - building on existing modules means faster delivery for new requirements.

## Sharing pipelines

In many pricing teams, each model or analysis gets its own bespoke dataset.  
That means re-running similar queries, applying the same cleaning steps, and creating near-identical extracts over and over again.

A shared, productionised data pipeline eliminates this duplication.  
The same curated dataset can feed:

- Multiple models
- Optimisation and scenario testing
- Performance monitoring dashboards
- Regulatory and business reporting

When a new requirement comes along, you simply extend the pipeline - rather than building a whole new one from scratch.

Benefits:

- Consistency - everyone works from the same validated data. 
- Efficiency - no more repeating the same prep work for every project.
- Adaptability - new data sources can be integrated once and used everywhere.
- Auditability - a single, well-documented process makes compliance checks straightforward.

---

## End-to-end systems

An end-to-end pricing system connects every stage of the pricing process - from data ingestion to live deployment - into a single, coherent workflow.

Instead of having separate, manual steps for each stage, the system runs as a coordinated sequence:

1. Data ingestion - raw data from internal and external sources is automatically collected, cleaned, and validated.
2. Feature engineering - business rules and transformations are applied in a consistent, reusable way.
3. Model training and selection - algorithms are trained, validated, and chosen based on clear performance metrics.
4. Business logic application - commercial adjustments, underwriting rules, and other non-model factors are layered in.
5. Impact analysis - changes are tested against historical data and simulations before release.
6. Deployment - prices and models are automatically published to the live rating engine.
7. Monitoring - ongoing tracking of performance, drift, and profitability, with automated alerts.

Why it matters:

- Speed - new strategies can move from concept to live deployment in days, not months.
- Quality control - each step is reproducible and tested, reducing the risk of errors.
- Continuous improvement - feedback from monitoring feeds directly into the next iteration.
- Resilience - the system can be maintained and evolved without relying on individual analysts’ knowledge.

By treating pricing as a connected system rather than a set of one-off tasks, you create a process that is faster, more reliable, and far easier to improve over time.
